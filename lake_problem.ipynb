{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import brentq as root\n",
    "from rhodium import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the lake problem\n",
    "def lake_problem(pollution_limit,\n",
    "         b = 0.42,        # decay rate for P in lake (0.42 = irreversible)\n",
    "         q = 2.0,         # recycling exponent\n",
    "         mean = 0.02,     # mean of natural inflows\n",
    "         stdev = 0.001,   # standard deviation of natural inflows\n",
    "         alpha = 0.4,     # utility from pollution\n",
    "         delta = 0.98,    # future utility discount rate\n",
    "         nsamples = 100): # monte carlo sampling of natural inflows\n",
    "    Pcrit = root(lambda x: x**q/(1+x**q) - b*x, 0.01, 1.5)\n",
    "    nvars = len(pollution_limit)\n",
    "    X = np.zeros((nvars,))\n",
    "    average_daily_P = np.zeros((nvars,))\n",
    "    decisions = np.array(pollution_limit)\n",
    "    reliability = 0.0\n",
    "\n",
    "    for _ in range(nsamples):\n",
    "        X[0] = 0.0\n",
    "\n",
    "        natural_inflows = np.random.lognormal(\n",
    "                math.log(mean**2 / math.sqrt(stdev**2 + mean**2)),\n",
    "                math.sqrt(math.log(1.0 + stdev**2 / mean**2)),\n",
    "                size = nvars)\n",
    "\n",
    "        for t in range(1,nvars):\n",
    "            X[t] = (1-b)*X[t-1] + X[t-1]**q/(1+X[t-1]**q) + decisions[t-1] + natural_inflows[t-1]\n",
    "            average_daily_P[t] += X[t]/float(nsamples)\n",
    "\n",
    "        reliability += np.sum(X < Pcrit)/float(nsamples*nvars)\n",
    "\n",
    "    max_P = np.max(average_daily_P)\n",
    "    utility = np.sum(alpha*decisions*np.power(delta,np.arange(nvars)))\n",
    "    inertia = np.sum(np.diff(decisions) > -0.02)/float(nvars-1)\n",
    "\n",
    "    return (max_P, utility, inertia, reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lake_problem)\n",
    "\n",
    "# Define all parameters to the model that we will be studying\n",
    "model.parameters = [Parameter(\"pollution_limit\"),\n",
    "                    Parameter(\"b\"),\n",
    "                    Parameter(\"q\"),\n",
    "                    Parameter(\"mean\"),\n",
    "                    Parameter(\"stdev\"),\n",
    "                    Parameter(\"delta\")]\n",
    "\n",
    "# Define the model outputs\n",
    "model.responses = [Response(\"max_P\", Response.MINIMIZE),\n",
    "                   Response(\"utility\", Response.MAXIMIZE),\n",
    "                   Response(\"inertia\", Response.MAXIMIZE),\n",
    "                   Response(\"reliability\", Response.MAXIMIZE)]\n",
    "\n",
    "# Define any constraints (can reference any parameter or response by name)\n",
    "#model.constraints = [Constraint(\"reliability >= 0.95\")]\n",
    "\n",
    "# Some parameters are levers that we control via our policy\n",
    "model.levers = [RealLever(\"pollution_limit\", 0.0, 0.1, length=100)]\n",
    "\n",
    "# Some parameters are exogeneous uncertainties, and we want to better\n",
    "# understand how these uncertainties impact our model and decision making\n",
    "# process\n",
    "model.uncertainties = [UniformUncertainty(\"b\", 0.1, 0.45),\n",
    "                       UniformUncertainty(\"q\", 2.0, 4.5),\n",
    "                       UniformUncertainty(\"mean\", 0.01, 0.05),\n",
    "                       UniformUncertainty(\"stdev\", 0.001, 0.005),\n",
    "                       UniformUncertainty(\"delta\", 0.93, 0.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the cache for storing intermediate results\n",
    "setup_cache(file=\"example.cache\")\n",
    "\n",
    "# Optimize the model or get cached results if they exist.  Note that the\n",
    "# call to optimize is wrapped in a lambda function to enable lazy evaluation.\n",
    "output = cache(\"output\", lambda: optimize(model, \"NSGAII\", 10000))\n",
    "\n",
    "# save the Pareto approximate set as a .csv file\n",
    "output.save('optimization_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
